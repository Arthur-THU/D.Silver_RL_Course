
# 第十课 经典游戏

课程ppt已上传为pdf。

## 简介

本章其实是课程外的内容，主要讲解了一些经典游戏领域AI的发展情况，也介绍了几种常用的算法。
关于这些围棋，西洋跳棋等等游戏的AI解决情况我就简单说，重点就说说MINMAX等等一些算法，详细参考ppt。
其实这些国际象棋，西洋跳棋等游戏，早在很多年前人类就败给计算机了，大部分的算法都是根据MINMAX算法来的。
区别大体是估值函数的不同，但是早期一般都是二元线性估值函数，结合了很多人工专家的手工特征以及强大的
多线程MINMAX搜索，可以取得十分好的成绩，但是这些其实不算AI，只是单纯的计算和搜索，没有加入强化学习。

当然后面逐渐开始加入强化学习和深度学习的算法了，广义策略迭代，值函数近似网络之类的，和传统的搜索一结合，
效果十分好，像去年大热的阿尔法狗就是如此，就是蒙特卡洛搜索和强化学习的结合，我的这篇博客
[Link](https://cryer.github.io/2018/06/mcts/)比较清楚的讲了蒙特卡洛树搜索和阿尔法元的算法，感兴趣的可以去详细看一下。

当然想了解阿尔法元代码具体实现的话，也可以看我的这个项目[AlphaZero_Quoridor](https://github.com/cryer/AlphaZero_Quoridor)
这是我为了熟悉阿尔法系列算法的一个联系项目，利用AlphaZero算法实现一个叫步步为营（Quoridor）的桌游。

## 目录

* MinMax
* TD-root
* TD-leaf
* TreeStrap 
* monte-carlo-tree-search

下面主要按照目录讲解这几个算法。

### MinMax

### TD-root
### TD-leaf
### TreeStrap
### monte-carlo-tree-search

蒙特卡洛树搜索我上面已经给我我一篇博客的链接了，里面说的很详细，博客末尾还有一个利用蒙特卡洛树搜索实现井字棋游戏的小例子，
[链接在这](https://github.com/cryer/monte-carlo-tree-search),感觉对算法还有点模糊的人建议仔细研究一遍这个例子的代码，
代码才是学习算法最优最完整的方法，而且例子很简单，代码量很少，很容易看懂。






