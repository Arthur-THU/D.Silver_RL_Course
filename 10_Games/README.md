
# 第十课 经典游戏

课程ppt已上传为pdf。

## 简介

本章其实是课程外的内容，主要讲解了一些经典游戏领域AI的发展情况，也介绍了几种常用的算法。
关于这些围棋，西洋跳棋等等游戏的AI解决情况我就简单说，重点就说说MINMAX等等一些算法，详细参考ppt。
其实这些国际象棋，西洋跳棋等游戏，早在很多年前人类就败给计算机了，大部分的算法都是根据MINMAX算法来的。
区别大体是估值函数的不同，但是早期一般都是二元线性估值函数，结合了很多人工专家的手工特征以及强大的
多线程MINMAX搜索，可以取得十分好的成绩，但是这些其实不算AI，只是单纯的计算和搜索，没有加入强化学习。

当然后面逐渐开始加入强化学习和深度学习的算法了，广义策略迭代，值函数近似网络之类的，和传统的搜索一结合，
效果十分好，像去年大热的阿尔法狗就是如此，就是蒙特卡洛搜索和强化学习的结合，我的这篇博客
[Link](https://cryer.github.io/2018/06/mcts/)比较清楚的讲了蒙特卡洛树搜索和阿尔法元的算法，感兴趣的可以去详细看一下。

当然想了解阿尔法元代码具体实现的话，也可以看我的这个项目[AlphaZero_Quoridor](https://github.com/cryer/AlphaZero_Quoridor)
这是我为了熟悉阿尔法系列算法的一个联系项目，利用AlphaZero算法实现一个叫步步为营（Quoridor）的桌游。

## 目录

* MinMax
* TD-root
* TD-leaf
* TreeStrap 
* monte-carlo-tree-search

下面主要按照目录讲解这几个算法。

### MinMax
MinMax是一种传统的树搜索方法，适用于二人零和博弈游戏，什么叫二人零和博弈游戏呢？二人就是玩家只有两个，零和则表示
玩家双方是互相对立的，利益关系是互补的，对黑方有优势，那么对白方就一定是劣势，而且优劣的数值大小是一样的。常见的一些
双人棋类都是这种类型。

形象化算法的流程如下：

![](https://github.com/cryer/D.Silver_RL_Course/raw/master/images/300.png)

这是一棵MinMax搜索树，max代表己方，min代表敌方，因为我们估值函数是站在自己的角度上的，所以分数越高对自己越有利，
越低对自己越不利，也就是对敌方越有利。树要从底往上看，最开始我们知道叶子结点的分值，然后max节点就取最大值，
因为max代表己方，我们自然想要分数高的。再往上一层的话，由于是min，对方，所以我们要考虑对方的最优情况，也就是选择分数最小的，
因为对面肯定不希望我分数高。这样一步步往上就可以求出根节点的分数。至于落子，如果根节点是max的话，落子就选择子节点分数最大的那个就行了。

那么底层的7,3，-4之类的分值是怎么来的呢？答案是通过估值函数算出来的，这个估值函数的定义各种各样，只要逻辑没问题其实都是有效果的，
区别只是效果好不好。那么为什么需要估值函数呢？其实如果我们可以就这样搜索到游戏结束的话，根本不需要估值函数，胜利就1，失败就-1，平就0；
但是由于硬件内存和速度的限制，我们往往无法搜索到结束，一般6,7层就已经很高了，这时候叶子结点游戏没有结束，所以无法用胜负来赋值，
只能定义估值函数了。为了方便理解估值函数，我说一个最简单的估值函数，那就是判断叶子节点的状态是否游戏结束，胜利就返回1，失败就返回-1，没有结束或者
平局都返回0.这就是一个最简单的估值函数，但是你可以想象一开始所有的值都是0，因此效果如何，需要你根据你的具体游戏，具体实验看看。

### TD-root
### TD-leaf
### TreeStrap
### monte-carlo-tree-search

蒙特卡洛树搜索我上面已经给我我一篇博客的链接了，里面说的很详细，博客末尾还有一个利用蒙特卡洛树搜索实现井字棋游戏的小例子，
[链接在这](https://github.com/cryer/monte-carlo-tree-search),感觉对算法还有点模糊的人建议仔细研究一遍这个例子的代码，
代码才是学习算法最优最完整的方法，而且例子很简单，代码量很少，很容易看懂。






